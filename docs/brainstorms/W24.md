# Wave 24 — Theatrical Replay for Import & Consolidation

> When a repo has already been imported or consolidated, replay cached results with cinematic pacing instead of instant "skipped" events or re-running the LLM. Brain graph builds node-by-node. Reasoning streams from cache.

### Required Skills (Wave 24)

- `vercel-react-best-practices` — React hook patterns and performance for the theatrical scheduler
- `threejs-animation` — useFrame-based spawn animations for graph nodes
- `next-best-practices` — API route patterns for replay detection

---

### WP-073: Create theatrical scheduler hook and add replay_manifest event type

- **Priority:** P0
- **Dependencies:** none
- **Files:** `hooks/useTheatricalScheduler.ts` (NEW), `lib/github/types.ts`, `lib/codex/types.ts`
- **Objective:** A reusable `useTheatricalScheduler` hook exists that accepts a batch of events and drips them to the UI at configurable per-event-type intervals, including character-by-character text streaming. Both event type unions include `"replay_manifest"`.
- **Implementation notes:**
  - Hook API: `useTheatricalScheduler(options)` returns `{ enqueue, isReplaying, remaining, flush, cancel }`
  - Options: `defaultIntervalMs`, `intervalOverrides: Record<string, number>`, `onEventRelease`, `onTextStreamChunk`, `onTextStreamComplete`, `onComplete`
  - Uses `useRef` for queue (avoids re-renders per tick), `useState` for `isReplaying`/`remaining`
  - Uses `setTimeout` chain (not `setInterval`) — each event gets its own delay via `intervalOverrides[event.type] ?? defaultIntervalMs`
  - Special `streamText` field on a `ScheduledEvent`: when present, scheduler chunks the text (~40 chars at ~35ms) and calls `onTextStreamChunk` with progressively accumulated text (matches existing server behavior where `reasoning_delta` carries full accumulated text)
  - `enqueue()` cancels any prior replay before starting a new one
  - Pacing defaults embedded in module:

    | Event Type               | Delay (ms) |
    | ------------------------ | ---------- |
    | `encoding_start`         | 150        |
    | `episode_created`        | 550        |
    | `pattern_detected`       | 700        |
    | `rule_promoted`          | 900        |
    | `contradiction_found`    | 600        |
    | `salience_updated`       | 350        |
    | `consolidation_start`    | 400        |
    | `consolidation_complete` | 200        |

  - In `lib/github/types.ts` (line 57): add `"replay_manifest"` to `ImportEventType` union
  - In `lib/codex/types.ts` (line 105): add `"replay_manifest"` to `ConsolidationEventType` union
  - Do NOT modify any component or API route files

- **Acceptance criteria:**
  - [ ] `hooks/useTheatricalScheduler.ts` exports the hook with full TypeScript types
  - [ ] Both type files include `"replay_manifest"` in their event type unions
  - [ ] `npx tsc --noEmit` passes
  - [ ] `npx vitest run` passes (no regressions)
- **Evidence:** TypeScript compiles, existing tests pass

---

### WP-074: Add import replay path to server endpoint

- **Priority:** P0
- **Dependencies:** WP-073
- **Files:** `app/api/github/import/route.ts`
- **Objective:** When all fetched PRs are already imported, the import endpoint emits `replay_manifest` followed by synthetic `episode_created` events from cached episode data instead of `episode_skipped` events.
- **Implementation notes:**
  - After `listExistingEpisodePrNumbers()` (line 220) and `fetchMergedPRs()` (line 214), check: `const allCached = pullRequests.length > 0 && pullRequests.every(pr => existingPrNumbers.has(pr.number))`
  - If `allCached`, enter replay path:
    1. Query existing episodes from Supabase: `SELECT id, title, source_pr_number, salience_score, pattern_key, the_pattern, triggers FROM episodes WHERE repo_id = ? AND source_pr_number = ANY(?)`
    2. Build a Map of `source_pr_number → episode` for ordered lookup
    3. Emit `{ type: "replay_manifest", data: { mode: "import_replay", total_episodes: N, repo_id } }`
    4. For each PR (in `pullRequests` order): emit `encoding_start`, then `episode_created` with `{ episode: cachedData, encoding_source: "cached" }`
    5. Emit `complete` with `{ total: existingEpisodes.length, failed: 0, skipped: 0, repo_id, replayed: true }`
    6. Skip the entire LLM encoding loop
  - Mixed mode (some cached, some new): proceed with existing behavior. Replay only when 100% cached.
  - Memory-fallback (line 221 currently returns `new Set()`): extend to query `listEpisodesForRepo()` from runtime store and build the existing PR numbers set. Apply same replay logic.
  - Reuse existing `ImportEpisodeSummary` type for cached episode shape — it matches the DB select columns exactly (line 274)
- **Acceptance criteria:**
  - [ ] Importing a previously-imported repo emits `replay_manifest` + `episode_created` (not `episode_skipped`)
  - [ ] Importing a repo with some new PRs proceeds with normal behavior (no replay)
  - [ ] `complete` event data includes `replayed: true` flag when in replay mode
  - [ ] Memory-fallback path also detects cached state
  - [ ] `npx tsc --noEmit` passes
- **Evidence:** SSE event stream from re-import shows `replay_manifest` + `episode_created` events

---

### WP-075: Add pop-in spawn animations to graph nodes and edges

- **Priority:** P1
- **Dependencies:** none
- **Files:** `components/brain/EpisodeNode.tsx`, `components/brain/RuleNode.tsx`, `components/brain/NeuralEdge.tsx`, `components/brain/BrainScene.tsx`, `components/brain/BrainGraph.tsx`
- **Required Skills:**
  - `threejs-animation` (useFrame-based spawn animations)
- **Objective:** Newly mounted graph nodes animate in with a scale-from-zero pop effect. Edges fade in with an opacity ramp. BrainScene and BrainGraph support separate node sets for layout (stable positions) vs rendering (incrementally revealed).
- **Implementation notes:**
  - **EpisodeNode.tsx**: Add `useRef<THREE.Mesh>` and a `spawnT` ref starting at 0. In `useFrame`, advance `spawnT` toward 1 at `delta * 3.5`. Apply ease-out cubic: `eased = 1 - Math.pow(1 - spawnT, 3)`. Set `meshRef.current.scale.setScalar(eased * baseScale)`. Add `ref={meshRef}` to the `<mesh>`. When `spawnT >= 1`, skip the useFrame work.
  - **RuleNode.tsx**: Same pattern as EpisodeNode.
  - **NeuralEdge.tsx**: Add a `spawnOpacity` ref starting at 0, ramp to target opacity over ~0.3s using `useFrame`. Apply to the `<Line opacity={...}>` prop. Note: `Line` from drei doesn't support ref-based opacity mutation easily — instead, use a state + useFrame pattern: `const [currentOpacity, setCurrentOpacity] = useState(0)` and ramp it in useFrame.
  - **BrainGraph.tsx**: Add optional `layoutNodes?: BrainNodeModel[]` and `layoutEdges?: BrainEdgeModel[]` props. Use `layoutNodes ?? nodes` and `layoutEdges ?? edges` for the `layoutNodes()` useMemo (line 110). Continue using `nodes` and `edges` for rendering (lines 124-179). This ensures positions are stable when the visible set grows incrementally.
  - **BrainScene.tsx**: Add optional `layoutNodes?: BrainNodeModel[]` and `layoutEdges?: BrainEdgeModel[]` props. Pass them through to `<BrainGraph>`.
  - Do NOT change the force-directed layout algorithm itself
  - Do NOT change any API routes or hooks
- **Acceptance criteria:**
  - [ ] New nodes entering the graph animate from scale 0 to full size (~0.3s)
  - [ ] New edges entering the graph fade from opacity 0 to target (~0.3s)
  - [ ] When `layoutNodes`/`layoutEdges` are provided, positions are computed from the layout set (not the render set)
  - [ ] When `layoutNodes`/`layoutEdges` are omitted, behavior is identical to current (backwards compatible)
  - [ ] `npx tsc --noEmit` passes
- **Evidence:** Visual confirmation of pop-in animation when nodes are added

---

### WP-076: Integrate theatrical scheduler into OnboardingFlow for import replay + graph sync

- **Priority:** P0
- **Dependencies:** WP-073, WP-074, WP-075
- **Files:** `components/onboarding/OnboardingFlow.tsx`
- **Objective:** When the import endpoint returns a `replay_manifest`, the OnboardingFlow queues events through the theatrical scheduler and reveals graph nodes one-by-one synchronized with the feed.
- **Implementation notes:**
  - Import `useTheatricalScheduler` from `hooks/useTheatricalScheduler`
  - Add state: `const [visibleNodeIds, setVisibleNodeIds] = useState<Set<string> | null>(null)` — `null` means show all (fresh mode), `Set` means incremental reveal (replay mode)
  - In `startImport()` (line 521), after the SSE stream starts:
    1. After the first chunk is parsed, check if any event has `type === "replay_manifest"` with `data.mode === "import_replay"`
    2. If replay detected:
       - Set `visibleNodeIds = new Set()` (empty — nothing visible yet)
       - Continue reading the entire SSE stream into a batch array (events arrive fast since no LLM)
       - After stream ends, feed batch to `scheduler.enqueue(batch)`
    3. If not replay: existing behavior unchanged (events go directly to state)
  - Scheduler callbacks:
    - `onEventRelease(event)`: push to `events` state. If `episode_created`, extract episode ID from `event.data.episode.id` and add `"episode-${id}"` to `visibleNodeIds` set (immutable update). If `complete`, set phase to "ready", set `activeRepoId`, clear `visibleNodeIds` to null.
    - `onComplete()`: final graph refresh
  - Compute filtered graph for BrainScene:
    ```ts
    const displayNodes = useMemo(() => {
      if (!visibleNodeIds) return graph.nodes;
      return graph.nodes.filter((n) => visibleNodeIds.has(n.id));
    }, [graph.nodes, visibleNodeIds]);
    const displayEdges = useMemo(() => {
      if (!visibleNodeIds) return graph.edges;
      return graph.edges.filter(
        (e) => visibleNodeIds.has(e.source) && visibleNodeIds.has(e.target)
      );
    }, [graph.edges, visibleNodeIds]);
    ```
  - Pass to BrainScene: `nodes={displayNodes}` `edges={displayEdges}` `layoutNodes={graph.nodes}` `layoutEdges={graph.edges}`
  - The `toActivityEvent()` function (line 112) already handles `episode_created` — no change needed there
  - Cancel scheduler on component unmount and on new import start
  - In `refreshGraph()` call at line 540 (start of import): this pre-loads the full graph. Good — it gives us the full node set for stable layout.
- **Acceptance criteria:**
  - [ ] Re-importing the demo repo shows episode cards appearing one-by-one with ~550ms gaps
  - [ ] Brain graph nodes pop in one-by-one synchronized with feed cards
  - [ ] Graph positions stay stable as nodes are added (no layout jitter)
  - [ ] Fresh imports (new repo, no cached data) work exactly as before
  - [ ] `npx tsc --noEmit` passes
- **Evidence:** Visual demonstration of theatrical import replay with synced graph animation

---

### WP-077: Add consolidation replay path (server + client)

- **Priority:** P0
- **Dependencies:** WP-073
- **Files:** `app/api/consolidate/route.ts`, `hooks/useConsolidationStream.ts`
- **Objective:** Fresh consolidation runs store reasoning text. When a completed run exists for a repo, replay its cached events through the theatrical scheduler with character-by-character reasoning streaming.
- **Implementation notes:**
  - **Server — `app/api/consolidate/route.ts`**:
    - **Store reasoning text**: In `runSupabaseConsolidation`, add a `let capturedReasoningText = ""` variable. In the `onReasoningComplete` callback (line 306), capture: `capturedReasoningText = text`. Include in summary (line 377): `reasoning_text: capturedReasoningText`. Same for `runMemoryFallbackConsolidation`.
    - **Detect completed run**: At the start of `runSupabaseConsolidation` (after selecting the repo, ~line 210), before the `Promise.all` that creates a new run:
      ```ts
      const { data: existingRun } = await supabase
        .from('consolidation_runs')
        .select('id, summary')
        .eq('repo_id', selectedRepo.id)
        .eq('status', 'completed')
        .order('completed_at', { ascending: false })
        .limit(1)
        .maybeSingle();
      ```
    - If `existingRun?.summary?.pack` exists, take the **replay path**:
      1. Fetch current episode and rule counts from DB (for the `consolidation_start` event data)
      2. Emit `{ type: "replay_manifest", data: { mode: "consolidation_replay", run_id: existingRun.id, has_reasoning: Boolean(existingRun.summary.reasoning_text) } }`
      3. Emit `consolidation_start` with episode/rule counts
      4. If `summary.reasoning_text`: emit `reasoning_start`, then `reasoning_complete` with full text
      5. For each `pack.patterns[]`: emit `pattern_detected`
      6. For each `pack.rules_to_promote[]`: emit `rule_promoted` (include confidence from pack)
      7. For each `pack.contradictions[]`: emit `contradiction_found`
      8. For each `pack.salience_updates[]`: emit `salience_updated`
      9. Emit `consolidation_complete` with existing summary
      10. Return — do NOT create a new consolidation_run, do NOT call the LLM
    - Memory-fallback: Use `latestCompletedRunForRepo()` from runtime store for same check
  - **Client — `hooks/useConsolidationStream.ts`**:
    - Import `useTheatricalScheduler`
    - In `runConsolidation()` (line 135): after opening the SSE stream, read ALL events into a buffer array first (the stream is fast for both replay and real runs — reasoning tokens still stream during real runs)
    - After stream ends, check if first meaningful event is `replay_manifest`:
      - **If replay**: transform events into `ScheduledEvent[]`. For `reasoning_complete` events that have text, set `streamText` field to trigger char-by-char streaming. Feed to `scheduler.enqueue()`.
      - Scheduler callbacks mirror the existing event processing loop (lines 198-231): `setPhase`, `setProgress`, `setEvents`, reasoning text management, summary extraction
      - **If not replay**: process events immediately using current logic (unchanged)
    - Wait — this changes the UX for fresh runs too (buffering all events before displaying). That's bad for live reasoning. **Revised approach**: Read events one-by-one as today. But peek at the first event — if it's `replay_manifest`, switch to batch+scheduler mode. If it's `consolidation_start` (no manifest), continue with existing streaming behavior.
    - Add scheduler cleanup in the `finally` block (line 238)
- **Acceptance criteria:**
  - [ ] Fresh consolidation stores `reasoning_text` in `consolidation_runs.summary`
  - [ ] Re-running consolidation on an already-consolidated repo emits `replay_manifest` + cached events (no LLM call)
  - [ ] Reasoning text streams character-by-character during replay
  - [ ] Dream phase stepper progresses through all phases during replay
  - [ ] Progress counters tick up as events are released
  - [ ] Fresh consolidation (no prior run) works exactly as before
  - [ ] Memory-fallback mode also supports replay detection
  - [ ] `npx tsc --noEmit` passes
  - [ ] `npx vitest run` passes
- **Evidence:** SSE stream from re-consolidation shows `replay_manifest`, ReasoningCard streams cached text, DreamState phases progress

---

## File Ownership Matrix

| File                                       | Wave | Issue(s) |
| ------------------------------------------ | ---- | -------- |
| `hooks/useTheatricalScheduler.ts` (NEW)    | 24   | WP-073   |
| `lib/github/types.ts`                      | 24   | WP-073   |
| `lib/codex/types.ts`                       | 24   | WP-073   |
| `app/api/github/import/route.ts`           | 24   | WP-074   |
| `components/brain/EpisodeNode.tsx`         | 24   | WP-075   |
| `components/brain/RuleNode.tsx`            | 24   | WP-075   |
| `components/brain/NeuralEdge.tsx`          | 24   | WP-075   |
| `components/brain/BrainScene.tsx`          | 24   | WP-075   |
| `components/brain/BrainGraph.tsx`          | 24   | WP-075   |
| `components/onboarding/OnboardingFlow.tsx` | 24   | WP-076   |
| `app/api/consolidate/route.ts`             | 24   | WP-077   |
| `hooks/useConsolidationStream.ts`          | 24   | WP-077   |

No within-wave file overlap.

## Parallelism Notes

- **WP-073 + WP-075**: parallel (no file overlap, no dependency)
- **WP-074**: sequential after WP-073 (needs `replay_manifest` type)
- **WP-077**: sequential after WP-073 (needs `replay_manifest` type + scheduler hook)
- **WP-074 + WP-077**: can be parallel with each other (both depend on WP-073, touch different files)
- **WP-076**: sequential after WP-073, WP-074, WP-075 (integrates all three)

```
WP-073 ──┬──→ WP-074 ──┬──→ WP-076
         │              │
WP-075 ──┘   WP-077 ───┘
         ↑              ↑
      (parallel)    (parallel)
```

## Wave Exit

- `npx tsc --noEmit` passes
- `npx vitest run` passes
- Re-importing the demo repo shows theatrical replay (~15-18s for 20 episodes, not instant)
- Brain graph nodes pop in one-by-one during import replay
- Re-running sleep cycle shows cached reasoning streaming + paced pattern/rule events
- Fresh import and fresh consolidation (no prior data) work exactly as before
- Memory-fallback mode supports replay detection

## Assumptions

- Wave 24 starts from `main` at commit `ca6f945`
- WP numbering continues from WP-072 (last WP in wave 25)
- No schema migration needed — `consolidation_runs.summary` is already JSONB, `reasoning_text` is just a new key
- The `@react-three/fiber` `useFrame` hook is available in the current Three.js version for spawn animations

## Output

On implementation, this wave plan will be written to `docs/waves/W24-73-77.md`.
